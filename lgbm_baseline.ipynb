{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM을 활용한 베이스라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/train_dataset'\n",
    "csv_file_path = os.path.join(data_dir, 'train_data.csv')\n",
    "df = pd.read_csv(csv_file_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.682739Z",
     "start_time": "2021-05-24T09:49:28.979Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "    df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "    \n",
    "    #유저들의 문제 풀이수, 정답 수, 정답률을 시간순으로 누적해서 계산\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount()\n",
    "    df['user_acc'] = df['user_correct_answer']/df['user_total_answer']\n",
    "\n",
    "    # testId와 KnowledgeTag의 전체 정답률은 한번에 계산\n",
    "    # 아래 데이터는 제출용 데이터셋에 대해서도 재사용\n",
    "    correct_t = df.groupby(['testId'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_t.columns = [\"test_mean\", 'test_sum']\n",
    "    correct_k = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_k.columns = [\"tag_mean\", 'tag_sum']\n",
    "\n",
    "    df = pd.merge(df, correct_t, on=['testId'], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=['KnowledgeTag'], how=\"left\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.683739Z",
     "start_time": "2021-05-24T09:49:28.981Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = feature_engineering(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.684739Z",
     "start_time": "2021-05-24T09:49:28.982Z"
    }
   },
   "outputs": [],
   "source": [
    "# train과 test 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n",
    "random.seed(42)\n",
    "def custom_train_test_split(df, ratio=0.7, split=True):\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "    \n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "\n",
    "    train = df[df['userID'].isin(user_ids)]\n",
    "    test = df[df['userID'].isin(user_ids) == False]\n",
    "\n",
    "    #test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test['userID'] != test['userID'].shift(-1)]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.686739Z",
     "start_time": "2021-05-24T09:49:28.984Z"
    }
   },
   "outputs": [],
   "source": [
    "# 유저별 분리\n",
    "train, test = custom_train_test_split(df)\n",
    "\n",
    "# 사용할 Feature 설정\n",
    "FEATS = ['KnowledgeTag', 'user_correct_answer', 'user_total_answer', \n",
    "         'user_acc', 'test_mean', 'test_sum', 'tag_mean','tag_sum']\n",
    "\n",
    "# X, y 값 분리\n",
    "y_train = train['answerCode']\n",
    "train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "y_test = test['answerCode']\n",
    "test = test.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.687739Z",
     "start_time": "2021-05-24T09:49:28.985Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.688736Z",
     "start_time": "2021-05-24T09:49:28.986Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train[FEATS], y_train)\n",
    "lgb_test = lgb.Dataset(test[FEATS], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.689738Z",
     "start_time": "2021-05-24T09:49:28.988Z"
    }
   },
   "outputs": [],
   "source": [
    "model = lgb.train(\n",
    "                    {'objective': 'binary'}, \n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_test],\n",
    "                    verbose_eval=100,\n",
    "                    num_boost_round=500,\n",
    "                    early_stopping_rounds=100\n",
    "                )\n",
    "\n",
    "preds = model.predict(test[FEATS])\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.690738Z",
     "start_time": "2021-05-24T09:49:28.989Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL MATPLOTLIB IN ADVANCE\n",
    "# _ = lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.691738Z",
     "start_time": "2021-05-24T09:49:28.992Z"
    }
   },
   "outputs": [],
   "source": [
    "# LOAD TESTDATA\n",
    "test_csv_file_path = os.path.join(data_dir, 'test_data.csv')\n",
    "test_df = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# LEAVE LAST INTERACTION ONLY\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "\n",
    "# DROP ANSWERCODE\n",
    "test_df = test_df.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.692739Z",
     "start_time": "2021-05-24T09:49:28.993Z"
    }
   },
   "outputs": [],
   "source": [
    "# MAKE PREDICTION\n",
    "total_preds = model.predict(test_df[FEATS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.694736Z",
     "start_time": "2021-05-24T09:49:28.995Z"
    }
   },
   "outputs": [],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, \"output.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
