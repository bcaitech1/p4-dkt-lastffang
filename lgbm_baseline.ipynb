{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM을 활용한 베이스라인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.375544Z",
     "start_time": "2021-05-24T09:49:28.999092Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "from pycaret.classification import *\n",
    "from pycaret.utils import check_metric\n",
    "from datetime import timedelta, timezone, datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Wandb 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb # Wandb 연결을 위해 library 불러오기\n",
    "from wandb.lightgbm import wandb_callback\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config 파일에서 wandb config에 남길 데이터를 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"seed\": 42,\n",
    "    \"split_ratio\": 0.7,\n",
    "    \"verbose_eval\": 100,\n",
    "    \"num_boost_round\": 500,\n",
    "    \"early_stopping_rounds\": 100,\n",
    "    \"feature_engineering\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.678737Z",
     "start_time": "2021-05-24T09:49:29.376581Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load Train Data\n",
    "data_dir = '/opt/ml/input/data/train_dataset'\n",
    "csv_file_path = os.path.join(data_dir, 'train_data.csv')\n",
    "df = pd.read_csv(csv_file_path, parse_dates=['Timestamp'])\n",
    "\n",
    "# LOAD TESTDATA\n",
    "test_csv_file_path = os.path.join(data_dir, 'test_data.csv')\n",
    "test_df = pd.read_csv(test_csv_file_path, parse_dates=['Timestamp'])\n",
    "\n",
    "answerCode2bool = {'userID':object,  'answerCode': 'int16', 'KnowledgeTag':object}\n",
    "df = df.astype(answerCode2bool)\n",
    "test_df = test_df.astype(answerCode2bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 각 문제 평균 뽑기\n",
    "testId_mean_sum = df.groupby(['testId'])['answerCode'].agg(['mean','sum']).to_dict()\n",
    "assessmentItemID_mean_sum = df.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum']).to_dict()\n",
    "KnowledgeTag_mean_sum = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum']).to_dict()\n",
    "\n",
    "# 맞춰야하는 문항 ID 파악\n",
    "set_assessmentItemID = set(test_df.loc[test_df.answerCode == -1, 'assessmentItemID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.682739Z",
     "start_time": "2021-05-24T09:49:28.979Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    # 문항이 중간에 비어있는 경우를 파악 (1,2,3,,5)\n",
    "    def assessmentItemID2item(x):\n",
    "        return int(x[-3:]) - 1  # 0 부터 시작하도록 \n",
    "    df['item'] = df.assessmentItemID.map(assessmentItemID2item)\n",
    "\n",
    "    item_size = df[['assessmentItemID', 'testId']].drop_duplicates().groupby('testId').size()\n",
    "    testId2maxlen = item_size.to_dict() # 중복해서 풀이할 놈들을 제거하기 위해\n",
    "\n",
    "    item_max = df.groupby('testId').item.max()\n",
    "    print(len(item_max[item_max + 1 != item_size]), '개의 시험지가 중간 문항이 빈다. item_order가 올바른 순서') # item_max는 0부터 시작하니까 + 1\n",
    "    shit_index = item_max[item_max +1 != item_size].index\n",
    "    shit_df = df.loc[df.testId.isin(shit_index),['assessmentItemID', 'testId']].drop_duplicates().sort_values('assessmentItemID')      \n",
    "    shit_df_group = shit_df.groupby('testId')\n",
    "\n",
    "    shitItemID2item = {}\n",
    "    for key in shit_df_group.groups:\n",
    "        for i, (k,_) in enumerate(shit_df_group.get_group(key).values):\n",
    "            shitItemID2item[k] = i\n",
    "        \n",
    "    def assessmentItemID2item_order(x):\n",
    "        if x in shitItemID2item:\n",
    "            return int(shitItemID2item[x])\n",
    "        return int(x[-3:]) - 1  # 0 부터 시작하도록 \n",
    "    df['item_order'] =  df.assessmentItemID.map(assessmentItemID2item_order)\n",
    "\n",
    "    #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "    df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "    \n",
    "    # 유저가 푼 시험지에 대해, 유저의 전체 정답/풀이횟수/정답률 계산 (3번 풀었으면 3배)\n",
    "    df_group = df.groupby(['userID','testId'])['answerCode']\n",
    "    df['user_total_correct_cnt'] = df_group.transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_ans_cnt'] = df_group.cumcount()\n",
    "    df['user_total_acc'] = df['user_total_correct_cnt'] / df['user_total_ans_cnt']\n",
    "\n",
    "    # 유저가 푼 시험지에 대해, 유저의 풀이 순서 계산 (시험지를 반복해서 풀었어도, 누적되지 않음)\n",
    "    # 특정 시험지를 얼마나 반복하여 풀었는지 계산 ( 2번 풀었다면, retest == 1)\n",
    "    df['test_size'] = df.testId.map(testId2maxlen)\n",
    "    df['retest'] = df['user_total_ans_cnt'] // df['test_size']\n",
    "    df['user_test_ans_cnt'] = df['user_total_ans_cnt'] % df['test_size']\n",
    "\n",
    "    # 각 시험지 당 유저의 정확도를 계산\n",
    "    df['user_test_correct_cnt'] = df.groupby(['userID','testId','retest'])['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_acc'] = df['user_test_correct_cnt']/df['user_test_ans_cnt']\n",
    "\n",
    "\n",
    "    # 아래의 피처는 다이나믹 합니다. 학습된 train의 평균값을 사용하지 않고, 새로 들어온 데이터의 평균 값을 사용합니다.\n",
    "    # # testId와 KnowledgeTag의 전체 정답률은 한번에 계산\n",
    "    # # 아래 데이터는 제출용 데이터셋에 대해서도 재사용\n",
    "    # correct_t = df.groupby(['testId'])['answerCode'].agg(['mean', 'sum'])\n",
    "    # correct_t.columns = [\"test_mean\", 'test_sum']\n",
    "    # correct_a = df.groupby(['assessmentItemID'])['answerCode'].agg(['mean', 'sum'])\n",
    "    # correct_a.columns = [\"ItemID_mean\", 'ItemID_sum']\n",
    "    # correct_k = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum'])\n",
    "    # correct_k.columns = [\"tag_mean\", 'tag_sum']\n",
    "    # df = pd.merge(df, correct_t, on=['testId'], how=\"left\")\n",
    "    # df = pd.merge(df, correct_a, on=['assessmentItemID'], how=\"left\")\n",
    "    # df = pd.merge(df, correct_k, on=['KnowledgeTag'], how=\"left\")\n",
    "\n",
    "    # 본 피처는 train에서 얻어진 값을 그대로 유지합니다.\n",
    "    df[\"test_mean\"] = df.testId.map(testId_mean_sum['mean'])\n",
    "    df['test_sum'] = df.testId.map(testId_mean_sum['sum'])\n",
    "    df[\"ItemID_mean\"] = df.assessmentItemID.map(assessmentItemID_mean_sum['mean'])\n",
    "    df['ItemID_sum'] = df.assessmentItemID.map(assessmentItemID_mean_sum['sum'])\n",
    "    df[\"tag_mean\"] = df.KnowledgeTag.map(KnowledgeTag_mean_sum['mean'])\n",
    "    df['tag_sum'] = df.KnowledgeTag.map(KnowledgeTag_mean_sum['sum'])\n",
    "    '''\n",
    "    #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "    df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "    \n",
    "    #유저들의 문제 풀이수, 정답 수, 정답률을 시간순으로 누적해서 계산\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount()\n",
    "    df['user_acc'] = df['user_correct_answer']/df['user_total_answer']\n",
    "\n",
    "    # testId와 KnowledgeTag의 전체 정답률은 한번에 계산\n",
    "    # 아래 데이터는 제출용 데이터셋에 대해서도 재사용\n",
    "    correct_t = df.groupby(['testId'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_t.columns = [\"test_mean\", 'test_sum']\n",
    "    correct_k = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_k.columns = [\"tag_mean\", 'tag_sum']\n",
    "    \n",
    "    # Feature Engineering 추가\n",
    "    df['assessment_category'] = df.apply(lambda row: int(row.assessmentItemID[2]), axis = 1)\n",
    "\n",
    "    df = pd.merge(df, correct_t, on=['testId'], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=['KnowledgeTag'], how=\"left\")\n",
    "    '''\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.683739Z",
     "start_time": "2021-05-24T09:49:28.981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 개의 시험지가 중간 문항이 빈다. item_order가 올바른 순서\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>item</th>\n",
       "      <th>item_order</th>\n",
       "      <th>user_total_correct_cnt</th>\n",
       "      <th>user_total_ans_cnt</th>\n",
       "      <th>user_total_acc</th>\n",
       "      <th>test_size</th>\n",
       "      <th>retest</th>\n",
       "      <th>user_test_ans_cnt</th>\n",
       "      <th>user_test_correct_cnt</th>\n",
       "      <th>user_acc</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_sum</th>\n",
       "      <th>ItemID_mean</th>\n",
       "      <th>ItemID_sum</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001001</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.982063</td>\n",
       "      <td>219</td>\n",
       "      <td>0.955022</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001002</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.964126</td>\n",
       "      <td>215</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001003</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>203</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001004</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.968610</td>\n",
       "      <td>216</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001005</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.941704</td>\n",
       "      <td>210</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>3040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userID assessmentItemID      testId  answerCode           Timestamp  \\\n",
       "0      0       A060001001  A060000001           1 2020-03-24 00:17:11   \n",
       "1      0       A060001002  A060000001           1 2020-03-24 00:17:14   \n",
       "2      0       A060001003  A060000001           1 2020-03-24 00:17:22   \n",
       "3      0       A060001004  A060000001           1 2020-03-24 00:17:29   \n",
       "4      0       A060001005  A060000001           1 2020-03-24 00:17:36   \n",
       "\n",
       "  KnowledgeTag  item  item_order  user_total_correct_cnt  user_total_ans_cnt  \\\n",
       "0         7224     0           0                     NaN                   0   \n",
       "1         7225     1           1                     1.0                   1   \n",
       "2         7225     2           2                     2.0                   2   \n",
       "3         7225     3           3                     3.0                   3   \n",
       "4         7225     4           4                     4.0                   4   \n",
       "\n",
       "   user_total_acc  test_size  retest  user_test_ans_cnt  \\\n",
       "0             NaN          6       0                  0   \n",
       "1             1.0          6       0                  1   \n",
       "2             1.0          6       0                  2   \n",
       "3             1.0          6       0                  3   \n",
       "4             1.0          6       0                  4   \n",
       "\n",
       "   user_test_correct_cnt  user_acc  test_mean  test_sum  ItemID_mean  \\\n",
       "0                    NaN       NaN   0.947683      1268     0.982063   \n",
       "1                    1.0       1.0   0.947683      1268     0.964126   \n",
       "2                    2.0       1.0   0.947683      1268     0.910314   \n",
       "3                    3.0       1.0   0.947683      1268     0.968610   \n",
       "4                    4.0       1.0   0.947683      1268     0.941704   \n",
       "\n",
       "   ItemID_sum  tag_mean  tag_sum  \n",
       "0         219  0.955022      637  \n",
       "1         215  0.913187     3040  \n",
       "2         203  0.913187     3040  \n",
       "3         216  0.913187     3040  \n",
       "4         210  0.913187     3040  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = feature_engineering(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 개의 시험지가 중간 문항이 빈다. item_order가 올바른 순서\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>item</th>\n",
       "      <th>item_order</th>\n",
       "      <th>user_total_correct_cnt</th>\n",
       "      <th>user_total_ans_cnt</th>\n",
       "      <th>user_total_acc</th>\n",
       "      <th>test_size</th>\n",
       "      <th>retest</th>\n",
       "      <th>user_test_ans_cnt</th>\n",
       "      <th>user_test_correct_cnt</th>\n",
       "      <th>user_acc</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_sum</th>\n",
       "      <th>ItemID_mean</th>\n",
       "      <th>ItemID_sum</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>3</td>\n",
       "      <td>A050133008</td>\n",
       "      <td>A050000133</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-10-26 13:13:57</td>\n",
       "      <td>5289</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.653970</td>\n",
       "      <td>1219</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>124</td>\n",
       "      <td>0.560703</td>\n",
       "      <td>1658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>4</td>\n",
       "      <td>A070146008</td>\n",
       "      <td>A070000146</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-12-27 02:47:54</td>\n",
       "      <td>9080</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.635949</td>\n",
       "      <td>697</td>\n",
       "      <td>0.598540</td>\n",
       "      <td>82</td>\n",
       "      <td>0.538664</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3023</th>\n",
       "      <td>13</td>\n",
       "      <td>A070111008</td>\n",
       "      <td>A070000111</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-12-27 04:35:09</td>\n",
       "      <td>9660</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.462209</td>\n",
       "      <td>795</td>\n",
       "      <td>0.376744</td>\n",
       "      <td>81</td>\n",
       "      <td>0.499044</td>\n",
       "      <td>1305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>17</td>\n",
       "      <td>A090064006</td>\n",
       "      <td>A090000064</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-10-30 05:48:37</td>\n",
       "      <td>2611</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.427536</td>\n",
       "      <td>236</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>24</td>\n",
       "      <td>0.408974</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4670</th>\n",
       "      <td>26</td>\n",
       "      <td>A060135007</td>\n",
       "      <td>A060000135</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-10-23 11:44:18</td>\n",
       "      <td>1422</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.634492</td>\n",
       "      <td>986</td>\n",
       "      <td>0.306306</td>\n",
       "      <td>68</td>\n",
       "      <td>0.610038</td>\n",
       "      <td>2589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     userID assessmentItemID      testId  answerCode           Timestamp  \\\n",
       "1035      3       A050133008  A050000133          -1 2020-10-26 13:13:57   \n",
       "1706      4       A070146008  A070000146          -1 2020-12-27 02:47:54   \n",
       "3023     13       A070111008  A070000111          -1 2020-12-27 04:35:09   \n",
       "4283     17       A090064006  A090000064          -1 2020-10-30 05:48:37   \n",
       "4670     26       A060135007  A060000135          -1 2020-10-23 11:44:18   \n",
       "\n",
       "     KnowledgeTag  item  item_order  user_total_correct_cnt  \\\n",
       "1035         5289     7           7                     6.0   \n",
       "1706         9080     7           7                     6.0   \n",
       "3023         9660     7           7                     3.0   \n",
       "4283         2611     5           5                     5.0   \n",
       "4670         1422     6           6                     4.0   \n",
       "\n",
       "      user_total_ans_cnt  user_total_acc  test_size  retest  \\\n",
       "1035                   7        0.857143          8       0   \n",
       "1706                   7        0.857143          8       0   \n",
       "3023                   7        0.428571          8       0   \n",
       "4283                   5        1.000000          6       0   \n",
       "4670                   6        0.666667          7       0   \n",
       "\n",
       "      user_test_ans_cnt  user_test_correct_cnt  user_acc  test_mean  test_sum  \\\n",
       "1035                  7                    6.0  0.857143   0.653970      1219   \n",
       "1706                  7                    6.0  0.857143   0.635949       697   \n",
       "3023                  7                    3.0  0.428571   0.462209       795   \n",
       "4283                  5                    5.0  1.000000   0.427536       236   \n",
       "4670                  6                    4.0  0.666667   0.634492       986   \n",
       "\n",
       "      ItemID_mean  ItemID_sum  tag_mean  tag_sum  \n",
       "1035     0.532189         124  0.560703     1658  \n",
       "1706     0.598540          82  0.538664     1226  \n",
       "3023     0.376744          81  0.499044     1305  \n",
       "4283     0.260870          24  0.408974      319  \n",
       "4670     0.306306          68  0.610038     2589  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = feature_engineering(test_df)\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train/Test 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.684739Z",
     "start_time": "2021-05-24T09:49:28.982Z"
    }
   },
   "outputs": [],
   "source": [
    "# train과 test 데이터셋은 사용자 별로 묶어서 분리를 해주어야함\n",
    "random.seed(config[\"seed\"])\n",
    "def custom_train_test_split(df, ratio=0.7, split=True):\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "    \n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "\n",
    "\n",
    "    train = df[df['userID'].isin(user_ids)]\n",
    "    test = df[df['userID'].isin(user_ids) == False]\n",
    "\n",
    "    #test데이터셋은 각 유저의 마지막 interaction만 추출\n",
    "    test = test[test['userID'] != test['userID'].shift(-1)]\n",
    "    return train, test\n",
    "\n",
    "def my_train_vali_split(df, filter_option = None, train_must_exist_leaderboard = False, ratio=0.5, seed = 23):\n",
    "    random.seed(seed)\n",
    "    # 리더보드와 동일 조건의 컬럼 수집\n",
    "    vali_full = df[(df['userID'] != df['userID'].shift(-1)) & (df.assessmentItemID.isin(set_assessmentItemID))].copy()\n",
    "    \n",
    "    # 리더보드와 동일 조건의 컬럼을 나누기\n",
    "    ratio_r = (1 - ratio)\n",
    "    vali_1 = vali_full.sample(frac=ratio_r, random_state = seed) # ratio가 1이면, ratio_r이 0이 되어, vali_1에 아무것도 할당되지 않는다.\n",
    "    vali_2 = vali_full.drop(vali_1.index)\n",
    "\n",
    "    # vali에 포함된 유저 목록 확인하기\n",
    "    vali_1_userID = set(vali_1.userID.values)\n",
    "    vali_2_userID = set(vali_2.userID.values)\n",
    "    \n",
    "    # vali에 없는 유저들만 train으로 데려오기\n",
    "    train_1 = df[ df['userID'].isin(vali_1_userID) == False ].copy()\n",
    "    train_2 = df[ df['userID'].isin(vali_2_userID) == False ].copy()\n",
    "    \n",
    "    # 마지막 응답만 가져올지 여부\n",
    "    if filter_option == '시험지마지막응답':\n",
    "        train_1 = train_1[train_1['testId'] != train_1['testId'].shift(-1)].copy()\n",
    "        train_2 = train_2[train_2['testId'] != train_2['testId'].shift(-1)].copy()\n",
    "    if filter_option == '사용자마지막응답':\n",
    "        train_1 = train_1[train_1['userID'] != train_1['userID'].shift(-1)].copy()\n",
    "        train_2 = train_2[train_2['userID'] != train_2['userID'].shift(-1)].copy()\n",
    "\n",
    "    # train도 리더보드에서 맞춰야하는 문제(444개 문제)만 볼지 여부\n",
    "    if train_must_exist_leaderboard:\n",
    "        train_1 = train_1[train_1.assessmentItemID.isin(set_assessmentItemID)].copy()\n",
    "        train_2 = train_2[train_2.assessmentItemID.isin(set_assessmentItemID)].copy()\n",
    "    \n",
    "    return train_1, vali_1, train_2, vali_2 , vali_full\n",
    "\n",
    "\n",
    "def test_train_vali_split(df, filter_option = None, train_must_exist_leaderboard = False, vali='Full', ratio=0.5, seed = 23):\n",
    "    random.seed(seed)\n",
    "    # 리더보드와 동일 조건의 컬럼 수집을 포기했다.\n",
    "    df = df[df.answerCode != -1].copy()\n",
    "    vali_full = df[(df['userID'] != df['userID'].shift(-1))].copy()\n",
    "\n",
    "    # 리더보드와 동일 조건의 컬럼을 나누기\n",
    "    ratio_r = (1 - ratio)\n",
    "    vali_1 = vali_full.sample(frac=ratio_r, random_state = seed) # ratio가 1이면, ratio_r이 0이 되어, vali_1에 아무것도 할당되지 않는다.\n",
    "    vali_2 = vali_full.drop(vali_1.index)\n",
    "\n",
    "    # vali에 포함된 유저 목록 확인하기\n",
    "    vali_1_userID = set(vali_1.userID.values)\n",
    "    vali_2_userID = set(vali_2.userID.values)\n",
    "    #vali_full_userID = set(vali_full.userID.values)\n",
    "\n",
    "    # vali 유저의 전 기록을 쓸 경우, 디폴트는 마지막 응답만 사용합니다.\n",
    "    if vali in ['Full', '시험지마지막응답']:\n",
    "        vali_1 = df[ df['userID'].isin(vali_1_userID) == True ].copy()\n",
    "        vali_2 = df[ df['userID'].isin(vali_2_userID) == True ].copy()\n",
    "        #vali_full = df[ df['userID'].isin(vali_full_userID) == True ].copy()\n",
    "\n",
    "    # vali 유저의 각 시험지 마지막 기록을 쓸 경우\n",
    "    if vali == '시험지마지막응답': \n",
    "        vali_1 = vali_1[(vali_1['testId'] != vali_1['testId'].shift(-1))].copy()\n",
    "        vali_2 = vali_2[(vali_2['testId'] != vali_2['testId'].shift(-1))].copy()\n",
    "        #vali_full = df[ df['userID'].isin(vali_full_userID) == True ].copy()\n",
    "        #vali_full = vali_full[(vali_full['testId'] != vali_full['testId'].shift(-1))].copy()\n",
    "\n",
    "    # vali에 없는 유저들만 train으로 데려오기\n",
    "    train_1 = df[ df['userID'].isin(vali_1_userID) == False ].copy()\n",
    "    train_2 = df[ df['userID'].isin(vali_2_userID) == False ].copy()\n",
    "    \n",
    "    # 마지막 응답만 가져올지 여부\n",
    "    if filter_option == '시험지마지막응답':\n",
    "        train_1 = train_1[train_1['testId'] != train_1['testId'].shift(-1)].copy()\n",
    "        train_2 = train_2[train_2['testId'] != train_2['testId'].shift(-1)].copy()\n",
    "    if filter_option == '사용자마지막응답':\n",
    "        train_1 = train_1[train_1['userID'] != train_1['userID'].shift(-1)].copy()\n",
    "        train_2 = train_2[train_2['userID'] != train_2['userID'].shift(-1)].copy()\n",
    "\n",
    "    # train도 리더보드에서 맞춰야하는 문제(444개 문제)만 볼지 여부\n",
    "    if train_must_exist_leaderboard:\n",
    "        train_1 = train_1[train_1.assessmentItemID.isin(set_assessmentItemID)].copy()\n",
    "        train_2 = train_2[train_2.assessmentItemID.isin(set_assessmentItemID)].copy()\n",
    "    \n",
    "    return train_1, vali_1, train_2, vali_2 , vali_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.686739Z",
     "start_time": "2021-05-24T09:49:28.984Z"
    }
   },
   "outputs": [],
   "source": [
    "# 유저별 분리\n",
    "train, test = custom_train_test_split(df, ratio=config[\"split_ratio\"])\n",
    "\n",
    "# 사용할 Feature 설정\n",
    "#FEATS = config[\"feature_engineering\"]\n",
    "FEATS = ['user_acc','ItemID_mean']\n",
    "FEATS += ['test_mean']\n",
    "config[\"feature_engineering\"] = FEATS\n",
    "\n",
    "# X, y 값 분리\n",
    "y_train = train['answerCode']\n",
    "train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "y_test = test['answerCode']\n",
    "test = test.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['userID', 'assessmentItemID', 'testId', 'Timestamp', 'KnowledgeTag',\n",
       "       'item', 'item_order', 'user_total_correct_cnt', 'user_total_ans_cnt',\n",
       "       'user_total_acc', 'test_size', 'retest', 'user_test_ans_cnt',\n",
       "       'user_test_correct_cnt', 'user_acc', 'test_mean', 'test_sum',\n",
       "       'ItemID_mean', 'ItemID_sum', 'tag_mean', 'tag_sum'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.687739Z",
     "start_time": "2021-05-24T09:49:28.985Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.688736Z",
     "start_time": "2021-05-24T09:49:28.986Z"
    }
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(train[FEATS], y_train)\n",
    "lgb_test = lgb.Dataset(test[FEATS], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 훈련 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exam_LGBM1(datasets,FEATS, categorical_features=[],numeric_features=[],seed=42):\n",
    "    train_1, vali_1, train_2, vali_2, vali_full = datasets\n",
    "    random.seed(seed)\n",
    "    settings = setup(data=train_1[FEATS], target='answerCode', train_size=0.8, categorical_features=categorical_features, numeric_features=numeric_features)\n",
    "    \n",
    "    lgbm = create_model('lightgbm', sort='AUC')\n",
    "    tuned_lgbm = tune_model(lgbm, optimize = 'AUC', fold = 10)\n",
    "    final_lgbm = finalize_model(tuned_lgbm)\n",
    "\n",
    "    predict_model(lgbm)\n",
    "    predict_model(tuned_lgbm)\n",
    "    predict_model(final_lgbm)\n",
    "\n",
    "    log = []\n",
    "    prediction = predict_model(final_lgbm, data=vali_1[FEATS], raw_score = True)\n",
    "    log.append(f\"학습에 사용안한 데이터: {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "    prediction = predict_model(final_lgbm, data=vali_2[FEATS], raw_score = True)\n",
    "    log.append(f\"학습에 사용한 데이터:  {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "    prediction = predict_model(final_lgbm, data=vali_full[FEATS], raw_score = True)\n",
    "    log.append(f\"모든 vali 데이터:    {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "        \n",
    "    return final_lgbm, log\n",
    "\n",
    "def exam_LGBM2( datasets ,FEATS, categorical_features=[],numeric_features=[],seed=47):\n",
    "    train_1, vali_1, train_2, vali_2, vali_full = datasets\n",
    "    random.seed(seed)\n",
    "    settings = setup(data=train_2[FEATS], target='answerCode', train_size=0.8, categorical_features=categorical_features, numeric_features=numeric_features)\n",
    "    \n",
    "    lgbm = create_model('lightgbm', sort='AUC')\n",
    "    tuned_lgbm = tune_model(lgbm, optimize = 'AUC', fold = 10)\n",
    "    final_lgbm = finalize_model(tuned_lgbm)\n",
    "    \n",
    "    predict_model(lgbm)\n",
    "    predict_model(tuned_lgbm)\n",
    "    predict_model(final_lgbm)\n",
    "    \n",
    "    log = []\n",
    "    prediction = predict_model(final_lgbm, data=vali_2[FEATS], raw_score = True)\n",
    "    log.append(f\"학습에 사용안한 데이터: {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "    prediction = predict_model(final_lgbm, data=vali_1[FEATS], raw_score = True)\n",
    "    log.append(f\"학습에 사용한 데이터:  {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "    prediction = predict_model(final_lgbm, data=vali_full[FEATS], raw_score = True)\n",
    "    log.append(f\"모든 vali 데이터:    {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")    \n",
    "    \n",
    "    return final_lgbm, log\n",
    "\n",
    "def exam_full(datasets ,FEATS, categorical_features=[],numeric_features=[],seed=47):\n",
    "    train_1, vali_1, train_2, vali_2, vali_full = datasets\n",
    "    random.seed(seed)\n",
    "    settings = setup(data=train_1[FEATS], target='answerCode', train_size=0.8, categorical_features=categorical_features, numeric_features=numeric_features)\n",
    "    \n",
    "    lgbm = create_model('lightgbm', sort='AUC')\n",
    "    tuned_lgbm = tune_model(lgbm, optimize = 'AUC', fold = 10)\n",
    "    final_lgbm = finalize_model(tuned_lgbm)\n",
    "\n",
    "    predict_model(lgbm)\n",
    "    predict_model(tuned_lgbm)\n",
    "    predict_model(final_lgbm)\n",
    "\n",
    "    log = []\n",
    "    prediction = predict_model(final_lgbm, data=vali_full[FEATS], raw_score = True)\n",
    "    log.append(f\"모든 vali 데이터:    {check_metric(prediction['answerCode'], prediction['Label'], metric = 'Accuracy')} ,{check_metric(prediction['answerCode'], prediction['Score_1'], metric = 'AUC')}\")\n",
    "    return final_lgbm, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.10.31 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.30<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">bumbling-bee-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/lastffang/p-stage-4-boosting\" target=\"_blank\">https://wandb.ai/lastffang/p-stage-4-boosting</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/lastffang/p-stage-4-boosting/runs/307tfsdf\" target=\"_blank\">https://wandb.ai/lastffang/p-stage-4-boosting/runs/307tfsdf</a><br/>\n",
       "                Run data is saved locally in <code>/opt/ml/p4-dkt-lastffang/wandb/run-20210603_080429-307tfsdf</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "wandb.login()\n",
    "\n",
    "wandb.init(project='p-stage-4-boosting', entity='lastffang', config=config)\n",
    "#wandb.init(project='p-stage-4-dkt', entity='newspring97', config=config) #TODO: 나중에 lastffang으로 바꿀 것\n",
    "#wandb.init(project='p-stage-4', entity='lastffang', config=config)\n",
    "wandb.run.name = \"sb-lgbm-seoil-features\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.689738Z",
     "start_time": "2021-05-24T09:49:28.988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1039565, number of negative: 546592\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 557\n",
      "[LightGBM] [Info] Number of data points in the train set: 1586157, number of used features: 3\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655399 -> initscore=0.642855\n",
      "[LightGBM] [Info] Start training from score 0.642855\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.489476\tvalid_1's binary_logloss: 0.531166\n",
      "[200]\ttraining's binary_logloss: 0.488572\tvalid_1's binary_logloss: 0.53085\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttraining's binary_logloss: 0.488933\tvalid_1's binary_logloss: 0.53066\n",
      "VALID AUC : 0.8121074339097595 ACC : 0.7448928749377179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "                    {'objective': 'binary'}, \n",
    "                    lgb_train,\n",
    "                    valid_sets=[lgb_train, lgb_test],\n",
    "                    verbose_eval=config[\"verbose_eval\"],\n",
    "                    num_boost_round=config[\"num_boost_round\"],\n",
    "                    early_stopping_rounds=config[\"early_stopping_rounds\"],\n",
    "                    callbacks=[wandb_callback()]\n",
    "                )\n",
    "\n",
    "preds = model.predict(test[FEATS])\n",
    "acc = accuracy_score(y_test, np.where(preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(f'VALID AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.690738Z",
     "start_time": "2021-05-24T09:49:28.989Z"
    }
   },
   "outputs": [],
   "source": [
    "# INSTALL MATPLOTLIB IN ADVANCE\n",
    "# _ = lgb.plot_importance(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.691738Z",
     "start_time": "2021-05-24T09:49:28.992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "411 개의 시험지가 중간 문항이 빈다. item_order가 올바른 순서\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Column not found: answerCode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0d8125630cb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# FEATURE ENGINEERING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_engineering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# LEAVE LAST INTERACTION ONLY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-d27d3f876e38>\u001b[0m in \u001b[0;36mfeature_engineering\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 유저가 푼 시험지에 대해, 유저의 전체 정답/풀이횟수/정답률 계산 (3번 풀었으면 3배)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mdf_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'userID'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'testId'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answerCode'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_total_correct_cnt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_total_ans_cnt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_group\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m             )\n\u001b[0;32m-> 1542\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# error: \"SelectionMixin\" has no attribute \"obj\"  [attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Column not found: {key}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: answerCode'"
     ]
    }
   ],
   "source": [
    "# FEATURE ENGINEERING\n",
    "test_df = feature_engineering(test_df)\n",
    "\n",
    "# LEAVE LAST INTERACTION ONLY\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]\n",
    "\n",
    "# DROP ANSWERCODE\n",
    "test_df = test_df.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.692739Z",
     "start_time": "2021-05-24T09:49:28.993Z"
    }
   },
   "outputs": [],
   "source": [
    "# MAKE PREDICTION\n",
    "total_preds = model.predict(test_df[FEATS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-24T09:49:29.694736Z",
     "start_time": "2021-05-24T09:49:28.995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : output/output_seoil_features.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, \"output_seoil_features.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)    \n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9595<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/opt/ml/p4-dkt-lastffang/wandb/run-20210603_080429-307tfsdf/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/opt/ml/p4-dkt-lastffang/wandb/run-20210603_080429-307tfsdf/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>training_binary_logloss</td><td>0.48805</td></tr><tr><td>valid_1_binary_logloss</td><td>0.5307</td></tr><tr><td>_runtime</td><td>21</td></tr><tr><td>_timestamp</td><td>1622707490</td></tr><tr><td>_step</td><td>255</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>training_binary_logloss</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_1_binary_logloss</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">bumbling-bee-9</strong>: <a href=\"https://wandb.ai/lastffang/p-stage-4-boosting/runs/307tfsdf\" target=\"_blank\">https://wandb.ai/lastffang/p-stage-4-boosting/runs/307tfsdf</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
